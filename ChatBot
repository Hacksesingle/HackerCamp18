import tensorflow as tf 
import data_utils
import seq2seq_model

def train():
	enc_train, dec_train = data_utils.prepare_custom_data(gConfig['working_directory'])
	train_set = read_data(enc_train, dec_train)

def seq2seq_f(encoder_inputs, decoder_inputs, do_decode):
	return tf.nn.seq2seq.embedding_attention_seq2seq(
		num_encoder_symbols = source_vocab_size,
		num_decoder_symbols = target_vocab_size,
		embedding_size = size,
		output_projection = output_projection,
		feed_previous = do_decode)

with tf.Session(config=config) as sess:

	model = create_model(sess, False)

	while True:
		sess.run(model)

		checkpoint_path = os.path.join(gConfig['working_directory'], "seq2seq.ckpt")
		model.saver.save(sess, checkpoint_path, global_step=model.global_step)

https://plus.google.com/photos/photo/101252193432304185718/6135710619046373458?sqid=107319989394811377133&ssid=4b4a8bd0-2ecd-466b-9820-c6fad452af38
https://dribbble.com/shots/2937858-Blink-Bot
https://www.google.co.in/imgres?imgurl=https%3A%2F%2Fres.cloudinary.com%2Fdgofwp0my%2Fimage%2Fupload%2Fv1498235436%2FDrax_Frequency_GIF_copy_bczyzs.gif&imgrefurl=https%3A%2F%2Fwww.drax.com%2Fenergy-policy%2Fneed-whole-country-frequency%2F&docid=Se2wmsEXFoAv4M&tbnid=wWSQmDNRhlPl_M%3A&vet=10ahUKEwiYlczo_9zeAhUQgUsFHUwCChgQMwg-KAAwAA..i&w=800&h=500&bih=981&biw=1853&q=frequency%20gif%20image&ved=0ahUKEwiYlczo_9zeAhUQgUsFHUwCChgQMwg-KAAwAA&iact=mrc&uact=8#h=500&imgdii=wWSQmDNRhlPl_M:&vet=10ahUKEwiYlczo_9zeAhUQgUsFHUwCChgQMwg-KAAwAA..i&w=800
